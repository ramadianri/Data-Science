# Data-Science
Repository containing copies of my data science journey, including notes and projects completed by me for **portfolio** purposes.

## Contents
You can either click on the files above or use the link below if Github fails to render IPython notebook correctly.
- [Hackathon Competition - Customer Segmentation](https://nbviewer.jupyter.org/github/ramadianri/Data-Science/blob/master/customer_segmentation.ipynb): An automobile company has plans to enter new markets with their existing products (P1, P2, P3, P4 and P5). In their existing market, the sales team has classified all customers into 4 segments (A, B, C, D). Then, they performed segmented outreach and communication for different segment of customers. This strategy has work exceptionally well for them. They plan to use the same strategy on new markets and have identified new potential customers. I predict the right group of the new customers, that are similar in specific ways relevant to marketing, by using LGBMClassifier.
- [Home Credit Default Risk](https://nbviewer.jupyter.org/github/ramadianri/Data-Science/blob/master/Home-Credit_default_risk.ipynb): The data is provided by Home Credit, a service dedicated to broaden financial inclusion for the unbanked population. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data. By joining together several datasets and using CatBoostClassifier model, I predict their clients' repayment abilities.
- [Kaggle Competition - House Prices, Advanced Regression Techniques](https://nbviewer.jupyter.org/github/ramadianri/Data-Science/blob/master/house_prices.ipynb): With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, I predict the final price of each home by using Gradient Boosting Regressor.
- [Kaggle Competition - Predict Future Sales](https://nbviewer.jupyter.org/github/ramadianri/Data-Science/blob/master/predict_future_sales.ipynb): This challenge serves as final project for the ”How to win a data science competition” Coursera course. The dataset consist of daily sales data, provided by one of the largest Russian software firms - 1C Company. I predict total sales for every product and store in the next month by using XGBRegressor model.
- [Credit Card Fraud](https://nbviewer.jupyter.org/github/ramadianri/Data-Science/blob/master/credit_card_fraud.ipynb): The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. I used SMOTE to dealing with unbalanced dataset and CatBoostClassifier model to predict and recognize fraudulent credit card transactions.
- [Loan Prediction Problem](https://nbviewer.jupyter.org/github/ramadianri/Data-Science/blob/master/loan_prediction_problem.ipynb): In this dataset, we need to predict whether or not to approve a loan based on the past information of the person. This is a classification problem and I use machine learning, Decision Tree Classifier model, to make the prediction.
- [Red Wine Quality](https://nbviewer.jupyter.org/github/ramadianri/Data-Science/blob/master/red_wine_quality.ipynb): The dataset is related to red variants of the Portuguese ”Vinho Verde” wine. I use Random Forest Classifier to determine which physiochemical properties make a wine ’good’.
