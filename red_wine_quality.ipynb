{"cells":[{"metadata":{},"cell_type":"markdown","source":"[This datasets](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009) is related to red variants of the Portuguese \"Vinho Verde\" wine. For more details, consult the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n\nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Import Libraries\nFirst, we import necessary libraries, such as:","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import The Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Quick Look at The Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Dataset's info","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Dataset's descriptive statistics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Check for missing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- Correlation of all the train features with target variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"(red_wine.corr()**2)['quality'].sort_values(ascending = False)[1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot some top of the most correlated one.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(red_wine['quality'], red_wine['alcohol']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(red_wine['quality'], red_wine['volatile acidity']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the distribution of quality feature by plotting it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(red_wine['quality'], data=red_wine);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the real world, people often 'take it simple' by just classified red wine into 2 qualities, good and bad. I will try the same approach by transforming it to binary labels. Let's say wine with quality > 6 is good and the remainder is bad.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['bad', 'good']\nbins = [2, 6, 8]\nred_wine['quality'] = pd.cut(red_wine['quality'], bins=bins, labels=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"red_wine = pd.get_dummies(red_wine, drop_first=True)\nred_wine","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating A Model\nWe begin by splitting data into two subsets: for training data and for testing data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = red_wine['quality_good']\nX = red_wine.drop(['quality_good'], axis = 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, we standarize the train and the test datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)\nprint('X_train_scaled mean : ', X_train.mean(axis=0))\nprint('X_train_scaled std  : ', X_train.std(axis=0))\n\nX_test = scaler.transform(X_test)\nprint('')\nprint('X_test_scaled mean : ', X_test.mean(axis=0))\nprint('X_test_scaled std  : ', X_test.std(axis=0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model training : Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#search grid for optimal parameters\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {'n_estimators' : [100,1000],\n              'max_depth': [None,10,100],\n              'max_features': ['auto','sqrt','log2']}\n\ngrid = GridSearchCV(model, param_grid, cv=5)\n\ngrid.fit(X_train, y_train)\n\nprint(grid.best_params_)\nprint(grid.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, classification_report\n\n#use the best model\nmodel = grid.best_estimator_\n\n#make a prediction\ny_predict = model.predict(X_test)\n\n#calculate Mean Squared Error and classification report\nprint('MSE : ', mean_squared_error(y_test, y_predict))\nprint(classification_report(y_test,y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}